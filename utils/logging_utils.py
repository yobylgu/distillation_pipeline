"""
Logging utilities for knowledge distillation training.
"""
import os
import csv
import json
import time
import logging
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional

def is_colab():
    """Check if running in Google Colab."""
    try:
        import google.colab
        return True
    except ImportError:
        return False

def setup_colab_logging():
    """Configure logging for Google Colab environments."""
    if is_colab():
        # Force unbuffered output in Colab
        import sys
        sys.stdout = sys.__stdout__
        sys.stderr = sys.__stderr__
        
        # Set environment variables for better logging
        os.environ['PYTHONUNBUFFERED'] = '1'
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        
        # Configure logging with immediate flush
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            force=True  # Override any existing configuration
        )
        
        return True
    return False

# TensorBoard support (Task 3.2)
try:
    from torch.utils.tensorboard import SummaryWriter
    TENSORBOARD_AVAILABLE = True
except ImportError:
    TENSORBOARD_AVAILABLE = False

class DistillationLogger:
    """
    Comprehensive logging system for knowledge distillation training.
    Tracks loss components, hyperparameters, and provides real-time monitoring.
    """
    
    def __init__(self, output_dir, loss_components=None, enable_tensorboard=True):
        self.output_dir = output_dir
        # Support for additional loss components
        if loss_components is None:
            loss_components = ['ce', 'kl', 'total']
        self.loss_components = loss_components
        self.loss_history = {comp: [] for comp in loss_components}
        
        self.hyperparams_history = []
        self.step_logs = []
        self.start_time = time.time()
        
        # Check if running in Colab and setup accordingly
        self.is_colab = setup_colab_logging()
        
        # Setup logging
        os.makedirs(output_dir, exist_ok=True)
        log_file = os.path.join(output_dir, 'distillation_log.txt')
        
        # Create file handler with explicit flushing for Colab compatibility
        file_handler = logging.FileHandler(log_file, mode='w')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        
        # Stream handler for console output
        stream_handler = logging.StreamHandler()
        stream_handler.setLevel(logging.INFO)
        stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        
        # Configure root logger
        self.logger = logging.getLogger(f'distillation_{id(self)}')  # Unique logger name
        self.logger.setLevel(logging.INFO)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(stream_handler)
        
        # Store handlers for manual flushing
        self.file_handler = file_handler
        self.stream_handler = stream_handler
        
        # Test logging immediately
        self.logger.info(f"Distillation logger initialized. Output dir: {output_dir}")
        self._flush_logs()
        
        # NEW: TensorBoard support (Task 3.2)
        self.tensorboard_writer = None
        if enable_tensorboard and TENSORBOARD_AVAILABLE:
            try:
                tensorboard_dir = os.path.join(output_dir, 'tensorboard')
                self.tensorboard_writer = SummaryWriter(tensorboard_dir)
                self.logger.info(f"TensorBoard logging enabled: {tensorboard_dir}")
            except Exception as e:
                self.logger.warning(f"Failed to initialize TensorBoard: {e}")
        elif enable_tensorboard and not TENSORBOARD_AVAILABLE:
            self.logger.warning("TensorBoard requested but not available. Install tensorboard package.")
        
        # Initialize CSV log file with dynamic columns
        self.csv_file = os.path.join(output_dir, 'training_metrics.csv')
        # NEW: Initialize per-step CSV file for detailed logging (Task 3.1)
        self.step_metrics_file = os.path.join(output_dir, 'step_metrics.csv')
        self._initialize_csv_headers()
    
    def _flush_logs(self):
        """Explicitly flush all logging handlers - crucial for Colab."""
        try:
            if hasattr(self, 'file_handler'):
                self.file_handler.flush()
            if hasattr(self, 'stream_handler'):
                self.stream_handler.flush()
        except Exception as e:
            print(f"Warning: Failed to flush logs: {e}")
    
    def debug_logging_status(self):
        """Debug method to check logging status - useful for Colab troubleshooting."""
        status = {
            'is_colab': self.is_colab,
            'output_dir': self.output_dir,
            'output_dir_exists': os.path.exists(self.output_dir),
            'log_file_path': os.path.join(self.output_dir, 'distillation_log.txt'),
            'csv_file_path': self.csv_file,
            'step_metrics_file_path': self.step_metrics_file,
        }
        
        # Check if files exist and are writable
        for key in ['log_file_path', 'csv_file_path', 'step_metrics_file_path']:
            file_path = status[key]
            status[f'{key}_exists'] = os.path.exists(file_path)
            if os.path.exists(file_path):
                status[f'{key}_size'] = os.path.getsize(file_path)
                try:
                    with open(file_path, 'a') as f:
                        status[f'{key}_writable'] = True
                except:
                    status[f'{key}_writable'] = False
        
        print("=== LOGGING DEBUG STATUS ===")
        for key, value in status.items():
            print(f"{key}: {value}")
        print("============================")
        
        # Test write to log file
        try:
            self.logger.info("DEBUG: Test log message from debug_logging_status()")
            self._flush_logs()
            print("✓ Test log message written successfully")
        except Exception as e:
            print(f"✗ Failed to write test log message: {e}")
        
        return status
    
    def _initialize_csv_headers(self):
        """Initialize CSV headers for both training metrics and detailed step metrics."""
        # Initialize main training metrics CSV (epoch-level)
        with open(self.csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            # Base columns
            columns = ['timestamp', 'epoch', 'step']
            # Add loss component columns dynamically
            for comp in self.loss_components:
                columns.append(f'{comp}_loss')
            # Add hyperparameter columns
            columns.extend(['temperature', 'alpha', 'learning_rate', 'elapsed_time'])
            writer.writerow(columns)
        
        # NEW: Initialize detailed step metrics CSV (Task 3.1)
        with open(self.step_metrics_file, 'w', newline='') as f:
            writer = csv.writer(f)
            # Enhanced columns including gradient norms
            columns = ['timestamp', 'epoch', 'step', 'mini_batch_idx']
            
            # Loss components (raw and weighted scalars)
            for comp in self.loss_components:
                columns.extend([f'{comp}_loss_raw', f'{comp}_loss_weighted'])
            
            # Gradient norms and training metrics
            columns.extend([
                'grad_norm_total',
                'grad_norm_encoder', 
                'grad_norm_decoder',
                'learning_rate',
                'temperature',
                'alpha',
                'effective_batch_size',
                'memory_usage_mb',
                'elapsed_time_seconds'
            ])
            
            # Component weights for multi-component loss
            for comp in self.loss_components:
                if comp != 'total':
                    columns.append(f'{comp}_weight')
            
            writer.writerow(columns)
    
    def log_step(self, epoch, step, losses, hyperparams, optimizer):
        """
        Log training step information.
        
        Args:
            epoch: Current epoch
            step: Current step
            losses: Dict with 'ce', 'kl', 'total' losses
            hyperparams: Dict with 'temperature', 'alpha'
            optimizer: Optimizer object to get learning rate
        """
        timestamp = datetime.now().isoformat()
        elapsed_time = time.time() - self.start_time
        lr = optimizer.param_groups[0]['lr']
        
        # Store in memory
        step_log = {
            'timestamp': timestamp,
            'epoch': epoch,
            'step': step,
            'losses': losses.copy(),
            'hyperparams': hyperparams.copy(),
            'learning_rate': lr,
            'elapsed_time': elapsed_time
        }
        self.step_logs.append(step_log)
        
        # Write to CSV with explicit flushing
        with open(self.csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            # Build row with all loss components dynamically
            row = [timestamp, epoch, step]
            for comp in self.loss_components:
                row.append(losses.get(comp, 0.0))
            row.extend([
                hyperparams['temperature'], hyperparams['alpha'], lr, elapsed_time
            ])
            writer.writerow(row)
            f.flush()  # Ensure immediate write to disk
        
        # Console output every 10 steps with enhanced info
        if step % 10 == 0:
            loss_str = f"Loss={losses.get('total', 0):.4f} ("
            loss_parts = []
            for comp in self.loss_components:
                if comp != 'total' and comp in losses and losses[comp] is not None:
                    # Only show non-zero values to avoid cluttering output
                    if losses[comp] == 0:
                        continue
                    loss_parts.append(f"{comp.upper()}={losses[comp]:.4f}")
            loss_str += ", ".join(loss_parts) + ")"
            
            self.logger.info(
                f"Epoch {epoch}, Step {step}: "
                f"{loss_str} "
                f"T={hyperparams['temperature']:.3f}, α={hyperparams['alpha']:.3f}"
            )
            self._flush_logs()  # Force flush after logging
        
        # NEW: Log to TensorBoard (Task 3.2)
        if self.tensorboard_writer:
            global_step = (epoch - 1) * 1000 + step  # Approximate global step
            
            # Log loss components
            for comp in self.loss_components:
                if comp in losses and losses[comp] is not None:
                    self.tensorboard_writer.add_scalar(f'Loss/{comp}', losses[comp], global_step)
            
            # Log hyperparameters
            self.tensorboard_writer.add_scalar('Hyperparams/temperature', hyperparams['temperature'], global_step)
            self.tensorboard_writer.add_scalar('Hyperparams/alpha', hyperparams['alpha'], global_step)
            self.tensorboard_writer.add_scalar('Hyperparams/learning_rate', lr, global_step)
            
            # Log metadata if available
            if '_meta' in losses:
                meta = losses['_meta']
                
                # Log component weights
                weights = meta.get('weights', {})
                for comp, weight in weights.items():
                    self.tensorboard_writer.add_scalar(f'Weights/{comp}', weight, global_step)
                
                # Log raw vs weighted scalars
                raw_scalars = meta.get('raw_scalars', {})
                weighted_scalars = meta.get('weighted_scalars', {})
                for comp in raw_scalars:
                    self.tensorboard_writer.add_scalar(f'Loss_Raw/{comp}', raw_scalars[comp], global_step)
                if weighted_scalars:
                    for comp in weighted_scalars:
                        self.tensorboard_writer.add_scalar(f'Loss_Weighted/{comp}', weighted_scalars[comp], global_step)
    
    def log_step_detailed(self, epoch, step, mini_batch_idx, losses, hyperparams, 
                         optimizer, model, effective_batch_size=None):
        """
        NEW: Log detailed step metrics including gradient norms (Task 3.1).
        
        Args:
            epoch: Current epoch
            step: Current step  
            mini_batch_idx: Index within the current step (for gradient accumulation)
            losses: Dict with loss components including metadata
            hyperparams: Dict with 'temperature', 'alpha'
            optimizer: Optimizer object to get learning rate
            model: Model for gradient norm computation
            effective_batch_size: Effective batch size (batch_size * gradient_accumulation_steps)
        """
        import torch
        import psutil
        
        timestamp = datetime.now().isoformat()
        elapsed_time = time.time() - self.start_time
        lr = optimizer.param_groups[0]['lr']
        
        # Compute gradient norms
        total_norm = 0.0
        encoder_norm = 0.0
        decoder_norm = 0.0
        
        for name, param in model.named_parameters():
            if param.grad is not None:
                param_norm = param.grad.data.norm(2)
                total_norm += param_norm.item() ** 2
                
                # Categorize gradients
                if 'encoder' in name:
                    encoder_norm += param_norm.item() ** 2
                elif 'decoder' in name:
                    decoder_norm += param_norm.item() ** 2
        
        total_norm = total_norm ** (1. / 2)
        encoder_norm = encoder_norm ** (1. / 2)
        decoder_norm = decoder_norm ** (1. / 2)
        
        # Get memory usage
        memory_usage = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # Extract metadata from losses if available
        metadata = losses.get('_meta', {})
        raw_scalars = metadata.get('raw_scalars', {})
        weighted_scalars = metadata.get('weighted_scalars', {})
        weights = metadata.get('weights', {})
        
        # Write detailed metrics to step CSV with explicit flushing
        with open(self.step_metrics_file, 'a', newline='') as f:
            writer = csv.writer(f)
            
            # Build row
            row = [timestamp, epoch, step, mini_batch_idx]
            
            # Loss components (raw and weighted)
            for comp in self.loss_components:
                raw_value = raw_scalars.get(comp, losses.get(comp, 0.0))
                weighted_value = weighted_scalars.get(comp, 0.0)
                row.extend([raw_value, weighted_value])
            
            # Gradient norms and training metrics
            row.extend([
                total_norm,
                encoder_norm, 
                decoder_norm,
                lr,
                hyperparams.get('temperature', 0.0),
                hyperparams.get('alpha', 0.0),
                effective_batch_size or 0,
                memory_usage,
                elapsed_time
            ])
            
            # Component weights
            for comp in self.loss_components:
                if comp != 'total':
                    row.append(weights.get(comp, 0.0))
            
            writer.writerow(row)
            f.flush()  # Ensure immediate write to disk
        
        # NEW: Log detailed metrics to TensorBoard (Task 3.2)
        if self.tensorboard_writer:
            global_step = (epoch - 1) * 1000 + step
            
            # Log gradient norms
            self.tensorboard_writer.add_scalar('Gradients/total_norm', total_norm, global_step)
            self.tensorboard_writer.add_scalar('Gradients/encoder_norm', encoder_norm, global_step)
            self.tensorboard_writer.add_scalar('Gradients/decoder_norm', decoder_norm, global_step)
            
            # Log training metrics
            self.tensorboard_writer.add_scalar('Training/effective_batch_size', effective_batch_size or 0, global_step)
            self.tensorboard_writer.add_scalar('System/memory_usage_mb', memory_usage, global_step)
            self.tensorboard_writer.add_scalar('Training/elapsed_time', elapsed_time, global_step)
            
            # Log mini-batch information
            self.tensorboard_writer.add_scalar('Training/mini_batch_idx', mini_batch_idx, global_step)
    
    def log_epoch(self, epoch, epoch_losses, val_metrics=None):
        """Log end-of-epoch summary with support for multiple loss components."""
        # Update loss history for all configured components
        for comp in self.loss_components:
            if comp in epoch_losses and epoch_losses[comp]:
                self.loss_history[comp].append(np.mean(epoch_losses[comp]))
        
        # Log epoch summary
        self.logger.info(f"Epoch {epoch} Summary:")
        for comp in self.loss_components:
            if comp in self.loss_history and self.loss_history[comp]:
                self.logger.info(f"  Avg {comp.upper()} Loss: {self.loss_history[comp][-1]:.4f}")
        
        if val_metrics:
            self.logger.info(f"  Validation F1: {val_metrics.get('f1', 0):.4f}")
            self.logger.info(f"  Validation BLEU: {val_metrics.get('bleu', 0):.4f}")
            # Log enhanced metrics if available
            if 'ast_validity' in val_metrics:
                self.logger.info(f"  AST Validity: {val_metrics['ast_validity']:.4f}")
            if 'code_quality_score' in val_metrics:
                self.logger.info(f"  Code Quality: {val_metrics['code_quality_score']:.4f}")
        
        self._flush_logs()  # Force flush after epoch summary
        
        # Save epoch summary to JSON
        epoch_summary = {
            'epoch': epoch,
            'avg_losses': {},
            'validation_metrics': val_metrics or {},
            'elapsed_time': time.time() - self.start_time
        }
        
        # Include all available loss components
        for comp in self.loss_history:
            if self.loss_history[comp]:
                epoch_summary['avg_losses'][comp] = self.loss_history[comp][-1]
        
        summary_file = os.path.join(self.output_dir, f'epoch_{epoch}_summary.json')
        with open(summary_file, 'w') as f:
            json.dump(epoch_summary, f, indent=2)
        
        # NEW: Log epoch metrics to TensorBoard (Task 3.2)
        if self.tensorboard_writer:
            # Log average epoch losses
            for comp in epoch_summary['avg_losses']:
                self.tensorboard_writer.add_scalar(f'Epoch_Loss/{comp}', epoch_summary['avg_losses'][comp], epoch)
            
            # Log validation metrics if available
            if val_metrics:
                for metric_name, metric_value in val_metrics.items():
                    if isinstance(metric_value, (int, float)):
                        self.tensorboard_writer.add_scalar(f'Validation/{metric_name}', metric_value, epoch)
            
            # Log training time
            self.tensorboard_writer.add_scalar('Training/epoch_time', epoch_summary['elapsed_time'], epoch)
    
    def get_loss_history(self):
        """Return loss history for dynamic scheduling."""
        return self.loss_history
    
    def save_final_report(self):
        """Save comprehensive training report."""
        final_losses = {}
        for comp in self.loss_components:
            if self.loss_history[comp]:
                final_losses[comp] = self.loss_history[comp][-1]
            else:
                final_losses[comp] = 0
        
        report = {
            'training_summary': {
                'total_steps': len(self.step_logs),
                'total_time': time.time() - self.start_time,
                'final_losses': final_losses
            },
            'loss_trends': self.loss_history,
            'hyperparameter_evolution': self.hyperparams_history
        }
        
        report_file = os.path.join(self.output_dir, 'training_report.json')
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        self.logger.info(f"Training report saved to {report_file}")
        self._flush_logs()  # Final flush
        
        # NEW: Close TensorBoard writer (Task 3.2)
        if self.tensorboard_writer:
            self.tensorboard_writer.close()
            self.logger.info("TensorBoard writer closed")
            self._flush_logs()
    
    def close(self):
        """
        NEW: Close logger and TensorBoard writer (Task 3.2).
        """
        if self.tensorboard_writer:
            self.tensorboard_writer.close()
            self.tensorboard_writer = None
            self.logger.info("TensorBoard writer closed")
